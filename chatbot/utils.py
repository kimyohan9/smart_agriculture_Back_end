import json
import requests  # requests ëª¨ë“ˆ ì¶”ê°€
import xmltodict
import os
import chromadb
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.output_parsers import JsonOutputParser
from dotenv import load_dotenv



def address_info(category: str, address: str):
    """ì£¼ì†Œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    if category not in {"ROAD", "PARCEL"}:
        return None  # JsonResponse ëŒ€ì‹  None ë°˜í™˜
    load_dotenv()
    vw_key = os.getenv("VWORLD_API_KEY")
    vw_URL = "https://api.vworld.kr/req/search"
    
    params = {'request': "search", 
              'key': vw_key, 
              'query': address, 
              'type': "address", 
              'category': category}
    
    response = requests.get(vw_URL, params=params)
    
    if response.status_code != 200:
        return None
    
    parsed_json = response.json()
    try:
        add_info = parsed_json["response"]["result"]['items'][0]
        return add_info
    except (KeyError, IndexError):
        return None


def soilexam(PNU_Code):
    """í† ì–‘ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    url = 'http://apis.data.go.kr/1390802/SoilEnviron/SoilExam/getSoilExam'
    load_dotenv()
    service_key = os.getenv("Soilexam_API_KEY")
    params = {'serviceKey': service_key, 'PNU_Code': PNU_Code}
    response = requests.get(url, params=params)

    if response.status_code != 200:
        return None
    
    try:
        response_json = xmltodict.parse(response.text)["response"]
        return response_json["body"]["items"]["item"]
    except (KeyError, TypeError):
        return None

class SoilExamRAG:
    """í† ì–‘ ì •ë³´ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, PNU_Code: str, persist_dir="my_vector_store"):
        load_dotenv()
        open_api_key = os.getenv("opneai_API_KEY")
        self.PNU_Code = PNU_Code        
        self.model = ChatOpenAI(model="gpt-4o-mini", api_key=open_api_key)
        self.embeddings = OpenAIEmbeddings(api_key=open_api_key)
        self.vector_store = Chroma(
                persist_directory=persist_dir,
                embedding_function=self.embeddings,
                )
        self.retriever = self.vector_store.as_retriever()
    
    def fetch_soil_data(self):
        """í† ì–‘ ë°ì´í„° ì¡°íšŒ"""
        return soilexam(self.PNU_Code)
    
    def retrieve_context(self, input_data):
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        if not input_data:
            return ""
        
        query = "\n".join([f"{key}: {value}" for key, value in input_data.items()])
        docs = self.retriever.invoke(query)
        return "\n".join([doc.page_content for doc in docs]) if docs else ""
    
    def get_recommendation(self):
        """í† ì–‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ì‘ë¬¼ ë°˜í™˜"""
        input_data = self.fetch_soil_data()
        if not input_data:
            return None
        
        prompt = PromptTemplate(
                template="""
                    ì•„ë˜ì˜ í† ì–‘ í™˜ê²½ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ê³¼ ë¹„êµí•˜ì—¬ ì í•©í•œ ì‘ë¬¼ì„ 3ì¢…ë¥˜ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
                    JSONì— ì…ë ¥í•  ê°’ì´ ì—†ëŠ” ê²½ìš° nullì„ ì…ë ¥í•´ ì£¼ì„¸ìš”. ë‹¨ crop ì—ëŠ” ë°˜ë“œì‹œ ì‘ë¬¼ ì´ë¦„ì´ ì…ë ¥ë˜ì•¼ í•©ë‹ˆë‹¤. 
                    ì¶”ì²œì´ìœ ì—ëŠ” ë¶€ì •ì ì¸ ë§ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì¶”ì²œí•œ ì‘ë¬¼ì´ ì‚¬ìš©ì ì…ë ¥ì˜ í† ì–‘ì •ë³´ì— ì í•©í•œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”. 
                    ë˜í•œ ì°¸ê³  ë¬¸ì„œì˜ ë²ˆí˜¸ë¥¼ ì•Œë ¤ ì£¼ì„¸ìš”.

            ğŸŒ± **ì‚¬ìš©ì ì…ë ¥ (í† ì–‘ ì •ë³´)**:
            {input_data}

            ğŸ“„ **ì°¸ê³  ë¬¸ì„œ (ì‘ë¬¼ë³„ ì ì • í™˜ê²½)**:
            {context}

             JSON í˜•ì‹:
             {{
                "recommendations": [
                 {{
                    "crop": "ì‘ë¬¼",
                    "optimal_conditions": {{
                        "ì‚°ë„(pH)": "ì ì • ì‚°ë„ ë²”ìœ„",
                        "ì „ê¸° ì „ë„ë„(SELC)" : "ì „ê¸° ì „ë„ë„",
                        "ì§ˆì‚°íƒœì§ˆì†Œ(NO3-N)" : "ì§ˆì‚°íƒœì§ˆì†Œ ë²”ìœ„",
                        "ìœ ê¸°ë¬¼(OM)": "ì ì • ìœ ê¸°ë¬¼ í•¨ëŸ‰",
                        "ìœ íš¨ì¸ì‚°(P)": "ìœ íš¨ì¸ì‚° ë²”ìœ„",
                        "ì¹¼ë¥¨(K)": "ì¹¼ë¥¨ ë²”ìœ„",
                        "ì¹¼ìŠ˜(Ca)": "ì¹¼ìŠ˜ ë²”ìœ„",
                        "ë§ˆê·¸ë„¤ìŠ˜(Mg)": "ë§ˆê·¸ë„¤ìŠ˜ ë²”ìœ„",                  
                        "ë¶•ì†Œ(B)" : "ë¶•ì†Œ"
                        }},
                "reason": "ì¶”ì²œ ì´ìœ "
            }},
            ...
            ]
            }}
            """,
        input_variables=["input_data", "context"]
        )

        context = self.retrieve_context(input_data)
        parser = JsonOutputParser()
        chain = prompt | self.model | parser
        response = chain.invoke({"input_data": input_data, "context": context})
        
        return response.get("recommendations", [])


# utils.pyì—ì„œ ì§ì ‘ ì‹¤í–‰ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì½”ë“œ
if __name__ == "__main__":
    print("ì´ íŒŒì¼ì€ Django í”„ë¡œì íŠ¸ì—ì„œ importí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.")