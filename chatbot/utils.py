import json
import requests  # requests ëª¨ë“ˆ ì¶”ê°€
import xmltodict
import os
import chromadb
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.output_parsers import JsonOutputParser
from dotenv import load_dotenv




def address_info(category: str, address: str):
    """ì£¼ì†Œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    if category not in {"ROAD", "PARCEL"}:
        return None  # JsonResponse ëŒ€ì‹  None ë°˜í™˜
    load_dotenv()
    vw_key = os.getenv("VWORLD_API_KEY")
    vw_URL = "https://api.vworld.kr/req/search"
    
    params = {'request': "search", 
              'key': vw_key, 
              'query': address, 
              'type': "address", 
              'category': category}
    
    add_response = requests.get(vw_URL, params=params)
    
    if add_response.status_code != 200:
        return None
    
    parsed_json = add_response.json()
    try:
        add_info = parsed_json["response"]["result"]['items'][0]
        return add_info
    except (KeyError, IndexError):
        return None


def soilexam(PNU_Code):
    """í† ì–‘ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    url = 'http://apis.data.go.kr/1390802/SoilEnviron/SoilExam/getSoilExam'
    load_dotenv()
    service_key = os.getenv("Soilexam_API_KEY")
    params = {'serviceKey': service_key, 'PNU_Code': PNU_Code}
    soil_response = requests.get(url, params=params)

    if soil_response.status_code != 200:
        return None
    
    try:
        response_json = xmltodict.parse(soil_response.text)["response"]
        return response_json["body"]["items"]["item"]
    except (KeyError, TypeError):
        return None

class SoilExamRAG:
    """í† ì–‘ ì •ë³´ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, PNU_Code: str, persist_dir="my_vector_store"):
        load_dotenv()
        open_api_key = os.getenv("opneai_API_KEY")
        self.PNU_Code = PNU_Code        
        self.model = ChatOpenAI(model="gpt-4o-mini", api_key=open_api_key)
        self.embeddings = OpenAIEmbeddings(api_key=open_api_key)
        self.vector_store = Chroma(
                persist_directory=persist_dir,
                embedding_function=self.embeddings,
                )
        self.retriever = self.vector_store.as_retriever()
    
    def fetch_soil_data(self):
        """í† ì–‘ ë°ì´í„° ì¡°íšŒ"""
        return soilexam(self.PNU_Code)
    
    def retrieve_context(self, input_data):
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        if not input_data:
            return ""
        
        query = "\n".join([f"{key}: {value}" for key, value in input_data.items()])
        docs = self.retriever.invoke(query)
        return "\n".join([doc.page_content for doc in docs]) if docs else ""
    
    def get_recommendation(self):
        """í† ì–‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ì‘ë¬¼ ë°˜í™˜"""
        input_data = self.fetch_soil_data()
        if input_data == 0:
            return None
        
        prompt = PromptTemplate(
            template="""
                ì•„ë˜ì˜ ì°¸ê³ ë¬¸ì„œë¥¼ ì‚¬ìš©ì ì…ë ¥ê³¼ ë¹„êµí•˜ì—¬ ì í•©í•œ ì‘ë¬¼ì„ 3ì¢…ë¥˜ê¹Œì§€ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•´ ì£¼ì„¸ìš”. ì¶”ì²œì€ ì°¸ê³  ë¬¸ì„œ ë‚´ìš© ë‚´ì—ì„œë§Œ ì§„í–‰í•´ ì£¼ì„¸ìš”. 
                ì°¸ê³ ë¬¸ì„œì—ëŠ” contextì˜ ë‚´ìš©ì¤‘ : 46ê³¼ ê°™ì€ ì²˜ìŒ ì²« ì¤„ ë‚´ìš©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ ì£¼ì„¸ìš”. 
                ì°¸ê³ ë¬¸ì„œê°€ ì—†ì„ ê²½ìš° ì¶”ì²œí•  ìˆ˜ ì—†ë‹¤ê³  ë‹µë³€í•´ ì£¼ì„¸ìš”. 

                ğŸŒ± **ì‚¬ìš©ì ì…ë ¥ (í† ì–‘ ì •ë³´)**:
                {input_data}

                ğŸ“„ **ì°¸ê³  ë¬¸ì„œ (ì‘ë¬¼ë³„ ì ì • í™˜ê²½)**:
                {context}

                JSON í˜•ì‹:
                {{
                    "ì¶”ì²œ ì‘ë¬¼": "<ì¶”ì²œí•  ì‘ë¬¼>",
                    "ì¶”ì²œ ì´ìœ ": "<ì¶”ì²œí•œ ì´ìœ >",
                    "ì°¸ê³  ë¬¸ì„œ": {context}
                }}
                """,
                input_variables=["input_data", "context"]
                )

    
        context = self.retrieve_context(input_data)

        parser = JsonOutputParser()

        chain = prompt | self.model | parser
        response = chain.invoke({"input_data": input_data, "context": context})

        return response


# utils.pyì—ì„œ ì§ì ‘ ì‹¤í–‰ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì½”ë“œ
if __name__ == "__main__":
    print("ì´ íŒŒì¼ì€ Django í”„ë¡œì íŠ¸ì—ì„œ importí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.")